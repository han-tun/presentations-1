---
title: "Taking the Pain Out of Census and Other Public Data"
subtitle: "Towards Frictionless, Transparent, Reproducible and Adabtable Analysis"
author: "Jens von Bergmann"
date: "2018/01/19"
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	dev="svg"
)
options(htmltools.dir.version = FALSE)
library("knitr")
library("utils")
library(tidyverse)
library(scales)
library(cancensus)
library(cancensusHelpers)
library(CANSIM2R)
library(cmhc)
library(rental)
library(sf)
options(servr.daemon = TRUE)
```



# Goals for this talk: 

1) Get people interested in census and other public data

2) Showcase some tools to work with census and other public data

3) Highlight some obstacles when working with census data

4) Help build a culture around civic data analysis



---

# So much data, so little time

Analysis and communication of results take a lot of time. So I built tools that facilitate and greatly speed this up while increasing *transparency*, *reproducability* and *adaptablility*. 

I want to showcase some of these tools dealing with


* Property Level Data
* Census Data
* CMHC Data
* ...

---
# Property Level Data

Property level data lets us explore housing issues at the individual property level. Great detail, but missing demographic variables. Also, sketchy coverage, lots of important variables not publicly accessible. Research institutions have access to more detailed and comprehensive data, but it's cumbersome to work with.

Examples:

* [Assessment (and related) Data](https://mountainmath.ca/map/assessment)
* [Teardown Index data story](https://mountainmath.ca/teardowns)
* [Tax Density](https://mountainmath.ca/assessment_gl/map)
* [Houses and Dirt Explorer](https://mountainmath.ca/assessment/split_map)

???
Sadly, most useful data is not publicly available. Can be accessed for research through cumbersome process and results can't be shared unless dropping detail and aggregated to high level.
---
background-image: url("phrn_files/figure-html/houses_and_dirt.png")
background-position: 50% 50%
background-size: 100%
class: center, bottom, inverse

# <a href="https://mountainmath.ca/assessment/split_map" target="_blank">Vancouver Houses And Dirt Demo</a>

???
A visualization that separates land and improvement values and allows stepping through time and exploring the effect of missing middle housing on prices.
---

# CensusMapper

CensusMapper is my answer to the inaccessibility of census data by non-experts. 

It allows instant and flexible mapping of census data. Canada wide. Maps can be narrated, saved and shared. By anyone.

---
background-image: url("https://doodles.mountainmath.ca/images/net_van.png")
background-position: 50% 50%
background-size: 100%
class: center, bottom, inverse

# <a href="https://censusmapper.ca/maps/731" target="_blank">CensusMapper Demo</a>

???
Lots of hidden features too that aren't accessible to general public. Don't have the resources to make them more user-friendly and release to public free to use.
---

# Maps aren't analysis

CensusMapper has APIs to facilitate deeper analysis. Open for all to use. 

[`cancensus`](https://github.com/mountainMath/cancensus) is an R package that seamlessly integrates census data into data analysis in R.

Let's try and understand the effects of the net migration patterns by age on the age distribution.

???
While we do need better data, we don't make good use of the data we already have. What's needed most is analysis.
---

# Age pyramids
How does the net migration effect the age distribution in each municipality?

```{r, message=FALSE, warning=FALSE, include=FALSE}
age_pyramid_styling <- list(
  scale_x_discrete(breaks=c(seq(0, 100, 5),"100+")),
  scale_y_continuous(labels = scales::comma),
  coord_flip(),
  scale_fill_brewer(palette = "Set1"),
  theme_bw(),
  labs(caption="cancensus, StatCan 2016 census"))
```

```{r canada_age, fig.height=3.5, fig.width=9, message=FALSE, warning=FALSE, dev='svg'}
plot_data <- get_age_data('CA16',list(CSD=c("5915022","5915004","5915055"))) %>% 
  rename(City=`Region Name`)
ggplot(plot_data, aes(x = Age, y = Population, fill = Gender)) + geom_bar(stat="identity") +
  facet_wrap("City",nrow=1, scales="free_x") + age_pyramid_styling
```
--
How to get the data to easily make these graphs?
???
Explain how net migration patterns lead to different age distributions.
---
background-image: url("images/api_tool.png")
background-position: 50% 50%
background-size: 100%
class: center, bottom, inverse

# <a href="https://censusmapper.ca/api" target="_blank">CensusMapper API Demo</a>

---

# Putting the "open" into StatCan open data

* CensusMapper made StatCan census data accessible to non-experts. For mapping and browsing.

* API extensions for non-mapping purposes make custom data extracts accessible to everyone.

* [`cancensus`](https://github.com/mountainMath/cancensus) is an R wrapper for these APIs that makes analysis accessible to everyone.

--

.center[**Well, maybe not everyone. But everyone in this room.**]

---

# Non-census data
CMHC provides great housing-related data. It's a pain to download, so I built an [pseudo-API in R](https://github.com/mountainMath/cmhc).

```{r, message=FALSE, warning=FALSE, include=FALSE}

# A function to read and tidy CMHC data
vacancy_rent_table_for <- function(geography,geography_type="CMA"){
  region_params=cmhc_region_params(geography = geography,type=geography_type)
  params=cmhc_timeseries_params(table_id = cmhc_table_list["Rms Vacancy Rate Time Series"],region=region_params)
  dat_vacancy=get_cmhc(params)
  title_x=attr(dat_vacancy,"title")
  dat_vacancy <- dat_vacancy %>% 
    select("X1","Total") %>%
    #mutate(Total=as.numeric(as.character(Total))/100) %>%
    rename(vacancy_rate=Total, X=X1)
  params=cmhc_timeseries_params(table_id = cmhc_table_list["Rms Rent Change Time Series"],region=region_params)
  dat_rent_change=get_cmhc(params)
  title_y=attr(dat_rent_change,"title")
  dat_rent_change <- dat_rent_change %>%
    select("X1","Total") %>%
    #mutate(Total=as.numeric(as.character(Total))/100) %>%
    rename(rent_change=Total, X=X1)
  dat=inner_join(dat_vacancy,dat_rent_change,by="X") %>% rename(Year=X)
  attr(dat,"region")=paste0(geography," ",geography_type)
  attr(dat,"labels")=c(title_x,title_y)
  return(dat)
}

get_vacancy_rent_data <- function(names,level){
  cmhc=bind_rows(lapply(names,function(x){return(vacancy_rent_table_for(x,"CMA")) %>% mutate(city=x)})) %>% 
    gather(key = "Series", value = "Rate",vacancy_rate:rent_change) %>%
    mutate(
      Series = case_when(
      .$Series == "vacancy_rate" ~ "Vacancy Rate",
      .$Series == "rent_change" ~ "Rent Change"),
      Year = as.Date(paste0(Year," 01"),format="%Y %B %d"),
      Rate=Rate/100)
  return(cmhc)  
}

vanancy_plot_options=list(
    # labs(#title="Vacancy Rate vs Change in Rent", 
    #    #subtitle ="Select Cities",
    #    caption="Source: CMHC Rms, code: https://github.com/mountainMath/cmhc"),
  scale_y_continuous(labels = scales::percent),
  xlab("") ,
  scale_x_date(breaks = seq(as.Date("1990-10-01"), as.Date("2016-10-01"), by="2 years"), 
    date_labels=format("%b %Y")),
  scale_color_manual(labels = c("% Rent Change\n(fixed sample)","Vacancy Rate"), values = c("darkgreen", "steelblue"), name = ""),
  theme_minimal(),
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
)

```


```{r, echo=TRUE, fig.height=4, fig.width=10, message=FALSE, warning=FALSE, dev="svg"}
cmhc <- get_vacancy_rent_data(c("Vancouver","Toronto","Calgary","Winnipeg"),"CMA")
ggplot(cmhc, aes(x = Year, y = Rate, color = Series)) + vanancy_plot_options +
  geom_line() + geom_point() + facet_wrap("city", ncol=2) 
```

???
CMHC has recently made finer data available. Sadly no APIs, but we can hack their data portal to speed up analysis. So we built a pseudo-API to consume it.

This graph shows the primary market vacancy rate and the fixed-sample rent change on the same axis. We note the clear inverse relationship between the two, with sometimes strong responses in non rent-controlled Calgary. And yes, rents do drop when the vacancy rate is high.
---
# Keeping the Census fresh
The 2016 census data is still quite up to date. But the clock is ticking, how can we keep it fresh? 

```{r, echo=FALSE, message=FALSE, warning=FALSE, dev="svg", fig.height=4, fig.width=7}
cma_uid="59933"
cache_file=paste0(getOption("cache_path"),"0510056_cache")
if (file.exists(cache_file)) {
  load(cache_file)
} else {
cansim_data <- CANSIM2R::getCANSIM("0510056",showLabels=FALSE,raw=TRUE) %>% 
  filter(Geographical.classification==cma_uid,AGE=="All ages",SEX=="Both sexes") %>% 
  mutate(type="CANSIM")
save(cansim_data,file=cache_file)
}

census_data <- do.call(rbind,lapply(c(2006,2011,2016),function(year){ 
  dataset=paste0("CA",substr(as.character(year),3,4))
  get_census(dataset=dataset,regions=list(CMA=cma_uid),vectors=c("v_CA16_1"),level="Regions") %>%
    mutate(GEO=`Region Name`,Value=Population,Ref_Date=year) %>%
    select(GEO,Value,Ref_Date,Population,Dwellings,Households) %>%
    mutate(type="Census")
  }
))

data <- rbind(cansim_data %>% select(Ref_Date,GEO,Value,type) %>% filter(Ref_Date >=2006),
              census_data %>% select(Ref_Date,GEO,Value,type) )

ggplot(data,aes(x=Ref_Date,y=Value, color=type)) +
  geom_line() +
  geom_point() +
  theme_bw()+
  #expand_limits(y = 0) +
  scale_y_continuous(labels=scales::comma) +
  scale_color_manual(name="Source", values=c(CANSIM="red",Census="blue")) +
  labs(title="Vancouver CMA Population Estimates",x="Year",y="Population",caption="CANSIM 051-0056, via CANSIM2R, Census via cancensus")
```

CANSIM data includes census undercounts. We can use relative changes in CANSIM data to estimate changes in Census data.

???
A retroactive look.
---
# Where in Vancouver did people move to?

CMHC building data can tell us where people go, we can use past censuses migration data to make educated guesses about demolition rates and the demographics of the new units.

```{r, echo=FALSE, fig.height=4, fig.width=7, message=FALSE, warning=FALSE, dev='svg'}

bg_color="#c0c0c0"
theme_opts<-list(theme(panel.grid.minor = element_blank(),
                       #panel.grid.major = element_blank(), #bug, not working
                       panel.grid.major = element_line(colour = bg_color),
                       panel.background = element_rect(fill = bg_color, colour = NA),
                       plot.background = element_rect(fill=bg_color, size=1,linetype="solid"),
                       axis.line = element_blank(),
                       axis.text.x = element_blank(),
                       axis.text.y = element_blank(),
                       axis.ticks = element_blank(),
                       axis.title.x = element_blank(),
                       axis.title.y = element_blank()))


cma="Vancouver"

census_cma=census_geography_list[[cma]]
cma_header=substr(census_cma, nchar(census_cma)-2,nchar(census_cma))


census_cma=census_geography_list[[cma]]
cma_header=substr(census_cma, nchar(census_cma)-2,nchar(census_cma))

#get all under construction data for Vancouver and pad CT GeoUIDs.

dates <- seq(from=as.Date('2011-05-01'), to=as.Date("2016-05-01"),by='months' )

# CMHC server is excrutiatingly slow, so good idea to cache data
cache_file=paste0(getOption("cache_path"),"van_completions")
if (file.exists(cache_file)) {
  load(cache_file)
} else {
completions <- do.call(rbind,lapply(dates,function(date){
  month=strftime(date,format="%m")
  year=strftime(date,format="%Y")
  c<-get_cmhc(cmhc_snapshot_params(
  table_id=cmhc_table_list["Scss Completions CT"],
  geography_id = cmhc_geography_list[[cma]],
  year = year,
  month = month)) %>% 
  mutate(GeoUID = paste0(cma_header,sprintf("%07.2f", X1)),
         date=date) %>% select(-X1,-X2)
  return(c)
  })) 
  save(completions,file=cache_file)
}

completions <- completions %>% 
  mutate(year=as.integer(substr(date,1,4)))

#completions <- completions %>% select(-date) %>% group_by(GeoUID) %>% summarise_all(sum)

geos11 <- get_census(dataset = 'CA11', regions=list(CMA=census_cma),level='CT',geo_format='sf') %>% 
  select(-`NHS Non-Return Rate`) %>%
  inner_join(
  completions %>% 
    filter(year>=2012) %>% 
        select(-date,-year) %>% 
    group_by(GeoUID) %>% 
    summarise_all(sum), by="GeoUID"
) 

geos06 <- get_census(dataset = 'CA06', regions=list(CMA=census_cma),level='CT',geo_format='sf') %>%
  inner_join(
      completions %>% 
      filter(year<2012) %>% 
        select(-date,-year) %>% 
      group_by(GeoUID) %>%
    summarise_all(sum), by="GeoUID"
  )

baseVars=c("Population","Dwellings","Households")
cmhcVars=c("Single","Semi-Detached","Row", "Apartment","All")
vars=c(baseVars,cmhcVars)
geos11 <- common_cts(geos06,geos11,vars) 

geos_data=rbind(geos06 %>% as.data.frame %>% select("GeoUID",cmhcVars),
                geos11 %>% as.data.frame %>% select("GeoUID",cmhcVars)) %>% 
  group_by(GeoUID) %>% summarize_all(sum,na.rm=TRUE)

geos=geos11 %>% select(GeoUID,baseVars) %>% inner_join(geos_data,by="GeoUID") %>%
  mutate(units=All) %>% #-Single/2) %>% #`Semi-Detached` + Row + Apartment) %>%
  mutate(`Estimated Dwellings`=Dwellings + units) 

breaks=c(-Inf,1,10,20,50,100,150,200,400,1000,Inf)
labels <- c(paste0("0 - ",breaks[2]))
for(i in 2:(length(breaks)-2)){
  labels[i] = paste(breaks[i],breaks[i+1], sep=" - ")
}
labels[length(breaks)-1]=paste0("Over ",breaks[length(breaks)-1])
#colors=c("darkred",(RColorBrewer::brewer.pal(length(labels)-1,"YlGnBu")))
labels=factor(labels, levels=labels)
colors=setNames(c("#808080",RColorBrewer::brewer.pal(length(labels)-1,"Greens")),labels)
#colors=factor(as.character(colors),levels=as.character(colors))

# categorize the numbers under contruction
geos$categories <- geos$units %>% cut(breaks=breaks, labels=labels)
total=sum(geos$units)

ggplot(geos) +
  geom_sf(aes(fill = categories), size = 0.05) +
  scale_fill_manual(labels=labels, values=colors, name = "Number of Units\nMay 2011 - May 2016") +
  ggtitle(paste0(cma, " CMA Completions (",prettyNum(total,big.mark = ",")," total)")) +
  theme_opts
```

???
Mixing in concurrent data sources like CMHC and CANSIM can extend the useful life of census data. Data APIs designed to be easily integrated facilitate this. And APIs make it simple to update analysis when new data becomes available.
---
# Reality Check
Census and CMHC timelines of completions don't always line up. CMHC does not track demolitions well.
```{r, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
geos16 <- get_census(dataset = 'CA16', regions=list(CMA=census_cma),level='CT',geo_format='sf')
geos16 <- common_cts(geos,geos16,baseVars)
geos_total <- inner_join(geos %>% 
                           mutate(Dwellings2011=Dwellings) %>%
                           select("GeoUID","Dwellings2011","units","Estimated Dwellings"), 
                         geos16 %>% as.data.frame %>% select(GeoUID,Dwellings),by="GeoUID") %>%
  mutate(difference=`Estimated Dwellings`-Dwellings)

diff_breaks=c(-Inf,-400,-200,-100,-50,50,100,200,400,Inf)
diff_labels <- c(paste0("Under ",diff_breaks[2]))
for(i in 2:(length(diff_breaks)-2)){
  diff_labels[i] = paste(diff_breaks[i],diff_breaks[i+1], sep=" - ")
}
diff_labels[length(diff_breaks)-1]=paste0("Over ",diff_breaks[length(diff_breaks)-1])
#colors=c("darkred",(RColorBrewer::brewer.pal(length(labels)-1,"YlGnBu")))
diff_labels=factor(diff_labels, levels=diff_labels)
diff_colors=setNames(RColorBrewer::brewer.pal(length(diff_labels),"PiYG"),diff_labels)
geos_total$diff_categories <- geos_total$difference %>% cut(breaks=diff_breaks, labels=diff_labels)

diff_total <- sum(geos_total$difference)

ggplot(geos_total) +
  geom_sf(aes(fill = diff_categories), size = 0.05) +
  scale_fill_manual(labels=diff_labels, values=diff_colors,name = "Estimate - Actual") +
  ggtitle(paste0(cma, " CMA Estimate - Actual (",prettyNum(diff_total,big.mark = ",")," difference)")) +
  theme_opts
```

???
Allows us to estimate where people moved to, and who these people are

---

# Rental Listings Data
Another important data source to inform how our city is changing is rental data.
```{r price_map, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE, dev='svg'}
library(rental)
start_time="2017-09-01"
end_time="2017-12-31"

geo=get_census(dataset = 'CA16',regions=list(CMA="59933"),geo_format='sf',level="CT")

cache_file="working_with_census_files/aggregate_listings.Rda"
if (file.exists(cache_file)) {
  load(cache_file)
} else {
ls <- get_listings(start_time,end_time,st_union(geo$geometry),beds=c(1),filter = 'unfurnished')

#cts=get_census(dataset = 'CA16',regions=list(CMA="59933"),geo_format='sf',level="CT")

min_listings=10

median_rent <- function(v){
  result <- ifelse(length(v)>=min_listings, median(v),NA)
  return(result)
}

#aggregate_listings <- aggregate(geo %>% select("GeoUID"),ls,function(x){x})

data <- aggregate(ls %>% select("price"),geo,median_rent)
save(data,file=cache_file)
}

cutoffs=as.integer(quantile(data$price, probs=seq(0,1,0.1), na.rm=TRUE))
labels=factor(as.character(seq(1,length(cutoffs)-1) %>% lapply(function(i){return(paste0(cutoffs[i]," - ",cutoffs[i+1]))})),order=TRUE)
colors=setNames(RColorBrewer::brewer.pal(length(labels),"RdYlBu"),labels)
data$discrete_price= data$price %>% cut(breaks=cutoffs, labels=labels)


ggplot() +
  geom_sf(data=geo, fill="#808080", size=0.1) +
  geom_sf(data=data, aes(fill = discrete_price), size=0.1) +
  scale_fill_brewer(palette='RdYlBu', direction=-1, na.value="#808080",name="Median Price") +
  labs(title=paste0(start_time," to ",end_time," 1 Bedroom Unfurnished Median Ask (n = ",format(nrow(ls),big.mark=","),")")) +
  theme_opts
```

???
Only showing data for areas with at least 10 listings.
---
# Challenges
One of the biggest challenges I face on a daily basis is need for robust and easily adaptable ecological inference models.

And [example](https://www.washingtonpost.com/news/monkey-cage/wp/2016/12/02/donald-trump-did-not-win-34-of-latino-vote-in-texas-he-won-much-less/?utm_term=.6d12061de8c4) Problem:

    Given the number of people that voted for Clinton and Trump in each precinct,
    as well as the number of Hispanic and White eligible voters and overall voter,
    turnout in each precinct, estimate the Latino turnout and share of Lations that
    voted for Trump.

We know the relationship between these quantities at the aggregate (ecological) level, but want to conclude something about the relationship at the individual voter level. 
---
# A Simple Example
To illustrate how to do this we consider an example where we know the answer. Take the number of households spending more than 30% of income on shelter costs in each census tract in Metro Vancouver, as well as the share of Owner and Tenant households. We want to know what share of Owner and Renter households each spend more than 30% of income on shelter costs.

```{r, fig.height=3, fig.width=6, message=FALSE, warning=FALSE, include=FALSE}
vectors=c("v_CA16_4886", # total shelter-to-income
          "v_CA16_4888", # total spending >30% income on shelter
          "v_CA16_4890", # total owner
          "v_CA16_4892", # pct_100 owners spending >30% income on shelter 
          "v_CA16_4897", # total renter
          "v_CA16_4899", # pct_100 renters spending >30% income on shelter
          "v_CA16_4891", # pct_100 owner households with mortgage
          "v_CA16_4898", # pct_100 renter households in subsidized housing
          "v_CA16_2540"  # pct_100 limat 
        ) 
ei_data <- get_census(dataset='CA16', 
                           regions=list(CMA="59933"), 
                           vectors=vectors, 
                           level='CT',
                           geo_format="sf", 
                           labels='short') 

ei_data <- ei_data %>%
  mutate(shelter_poor=v_CA16_4888/v_CA16_4886,
         shelter_ok = 1 - shelter_poor,
         sum = v_CA16_4890 + v_CA16_4897,
         owner_pct = v_CA16_4890/sum,
         renter_pct = v_CA16_4897/sum,
         total = as.integer(v_CA16_4886),
         rent_poor = v_CA16_4899/100.0,
         house_poor = v_CA16_4892/100.0,
         mortgage = v_CA16_4891/100,
         subsidized = v_CA16_4898/100,
         limat = v_CA16_2540/100)
```

```{r, echo=FALSE, fig.height=4, fig.width=6, message=FALSE, warning=FALSE}
ei_data_fit <- glm(shelter_poor ~ renter_pct, data=ei_data)
predicted_ei <- data.frame(shelter_poor = predict(ei_data_fit, ei_data), renter_pct=ei_data$renter_pct)
ggplot(ei_data,aes(x=shelter_poor,y=renter_pct,color=limat)) + 
  geom_point()+#aes(size=total)) +
  scale_color_viridis_c(option="magma", labels=scales::percent) +
  geom_line(color='red',data = predicted_ei) +
  scale_x_continuous(labels=scales::percent) +
  scale_y_continuous(labels=scales::percent) +
  labs(title="CTs in Vancouver CMA",x="Share Spendig >30% of Income on Shelter Cost", 
       y="Share of Tenant Households", color="LIMAT", size="Households")
```

---
# Ecological Inference
Ecological inference builds a distribution over the space of our quantities of interest, the share of owners $\beta^w$ and the share of renters $\beta^b$ spending more than 30% of income on shelter.

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(ei)
filtered_ei_data <- ei_data %>% na.omit
data <-  filtered_ei_data %>% dplyr::select(shelter_poor, renter_pct, total, GeoUID, mortgage,subsidized,limat)
truth <- filtered_ei_data %>% dplyr::select(rent_poor, house_poor)
cache_file=paste0(getOption("cache_path"),"ei_data.Rda")
if (file.exists(cache_file)) { # speed things up
  load(cache_file)
} else {
result <- ei(formula = shelter_poor ~ renter_pct, 
             data=data,
             id="GeoUID",
             truth=truth,
             total="total",
             Zw="limat",Zb="limat")
  save(result,file=cache_file)
}
estimate <- eiread(result,"maggs")
goodman <- eiread(result,"goodman")

```




```{r, echo=FALSE, fig.height=4.5, fig.width=5}
plot(result, "tomog")
```

---

```{r, echo=FALSE, fig.height=5, fig.width=6}
plot(result, "tomogE")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

paste0("Tenants spending > 30% of income on shelter: ",format_percent(estimate[1]), 
             ", Goodman Reg: ",format_percent(goodman["BetaB","Estimate"]),
             ", truth: 44.7%"
             )
paste0("Owners spending > 30% of income on shelter: ",format_percent(estimate[2]),
              ", Goodman Reg: ",format_percent(goodman["BetaW","Estimate"]),
             ", truth: 27.6%"
            )

```

```{r, eval=FALSE, include=FALSE}
plot_data=cbind(filtered_ei_data,betaw=result$betaw)
ggplot(plot_data,aes(x=betaw,y=house_poor,size=total, color=limat)) + geom_point()
```

---
# Mapping the Residuals
A geographic check of the residuals reveals where we went wrong. In regular examples we don't have this information and have to rely on other tests to understand the presence of biases in our model and refine it.

```{r, echo=FALSE, fig.height=4.5, fig.width=6, message=FALSE, warning=FALSE}
ei_data2 <- left_join(ei_data,tibble(GeoUID=result$id,betaw=result$betaw),by="GeoUID") %>% 
  mutate(Estimate=betaw, `House Poor`=house_poor,Difference=betaw-house_poor) 
# ggplot(ei_data2 %>% gather(key="type",value="Share",c("Estimate","House Poor")), aes(fill=Share)) +
#   geom_sf(size=0.1) +
#   facet_wrap("type",nrow=1) + theme_opts
ggplot(ei_data2, aes(fill=Difference)) +
  scale_fill_viridis_c() +
  geom_sf(size=0.1) + 
  theme_opts +
  labs(title="Estimate - Actual")
```
```{r, include=FALSE}
detach(package:ei)
detach(package:eiPack)
detach(package:MASS)
```

---

# Reproducibility, Transparancy, Adaptability
We need to adopt a more collaborative approach to understanding civic issues.

.pull-left[
### Notebooks
A data Notebook is a document that integrates explanatory text and data analysis. In its crudest form this could be an Excel spreadsheet with embedded comments. At the other end of the spectrum are R or Python Notebooks. In fact, this presentation is an R notebook and [lives on GitHub](https://github.com/mountainMath/presentations/blob/master/working_with_census.Rmd). It contains
all the code to reproduce the graphs in the presentation.
]
.pull-right[
### APIs
In order to be reproducible, any analysis should ship with code and the data. But that's not very adaptable. To be adaptable, the data should come through APIs. That way one can easily make changes that requires slightly different data, e.g. use related census variables, other time frames or geographic regions.
]
--

.center[**Should become standard as base for public policy.**]

--

I will leave you with some quiz questions.

???
This is key to building an ecosystem of people and groups that collaborate to advance understanding of civic issues. Opening up your analysis for everyone to see and pluck apart might be uncomfortable at first, but it's essential to take the discussion to the next level. It increases transparency and trust, and allows others to build on your work.
---
# Question 1

Has affordability in the City of Vancouver gotten better or worse?

--

```{r, message=FALSE, warning=FALSE, include=FALSE}
caption="StatCan census 2006, 2011 NHS, 2016 via cancensus & CensusMapper"
format_percent <- function(x){return(paste0(round(x*100,1),"%"))}
format_number <- function(x){return(format(x,big.mark = ","))}

affordability_graph_for <- function(regions, text_size=4) {
vectors_2016=c("v_CA16_4892","v_CA16_4899")
vectors_2011=c("v_CA11N_2283","v_CA11N_2290")
vectors_2006=c("v_CA06_2049","v_CA06_2051","v_CA06_2053","v_CA06_2056")
data_2016=get_census("CA16",level="Regions",regions=regions,vectors=vectors_2016,labels="short") %>%
  mutate(Owner=v_CA16_4892/100, Tenant=v_CA16_4899/100, Year=2016) 
data_2011=get_census("CA11",level="Regions",regions=regions,vectors=vectors_2011,labels="short") %>%
  mutate(Owner=v_CA11N_2283/100, Tenant=v_CA11N_2290/100, Year=2011) 
data_2006=get_census("CA06",level="Regions",regions=regions,vectors=vectors_2006,labels="short") %>%
  mutate(Owner=v_CA06_2056/v_CA06_2053, Tenant=v_CA06_2051/v_CA06_2049, Year=2006)

data <- do.call(rbind,list(
  data_2016 %>% select("Region Name", "Owner", "Tenant", "Year"),
  data_2011 %>% select("Region Name", "Owner", "Tenant", "Year"),
  data_2006 %>% select("Region Name", "Owner", "Tenant", "Year")
                      )) %>% mutate(Region=`Region Name`) %>% 
         gather(key="Tenure", value="Count",c("Owner","Tenant")) %>%
         mutate(Year=factor(Year,levels=c(2006,2011,2016),ordered=TRUE))

g1 <- ggplot(data, 
       aes(x=factor(Year), y=Count, fill=Tenure)) +
  geom_bar(stat="identity",position="dodge") +
  scale_y_continuous(labels = scales::percent) +
  labs(x="Year", y="Share", title="Households spending 30% or more on shelter") +
  geom_text(aes(label=format_percent(Count)),vjust=-0.5, position = position_dodge(width = 1), size=text_size) +
  expand_limits(y=max(data$Count)*1.15) +
  facet_wrap("Region",ncol=2) +
  theme_bw()
return(g1)
}        

multiple_graph_for <- function(regions, text_size=4) {
vectors_2016=c("v_CA16_4985","v_CA16_4890","v_CA16_4894","v_CA16_4897","v_CA16_4901")
vectors_2011=c("v_CA11N_2563","v_CA11N_2281","v_CA11N_2285","v_CA11N_2288","v_CA11N_2292")
vectors_2006=c("v_CA06_2001","v_CA06_2049","v_CA06_2050","v_CA06_2053","v_CA06_2055")
data_2016=get_census("CA16",level="Regions",regions=regions,vectors=vectors_2016,labels="short") %>%
  mutate(Ratio=(v_CA16_4890*v_CA16_4894+v_CA16_4897*v_CA16_4901)/(v_CA16_4890+v_CA16_4897)*12/v_CA16_4985, Year=2016) 
data_2011=get_census("CA11",level="Regions",regions=regions,vectors=vectors_2011,labels="short") %>%
  mutate(Ratio=(v_CA11N_2281*v_CA11N_2285+v_CA11N_2288*v_CA11N_2292)/(v_CA11N_2281+v_CA11N_2288)*12/v_CA11N_2563, Year=2011) 
data_2006=get_census("CA06",level="Regions",regions=regions,vectors=vectors_2006,labels="short") %>%
  mutate(Ratio=(v_CA06_2049*v_CA06_2050+v_CA06_2053*v_CA06_2055)/(v_CA06_2049+v_CA06_2053)*12/v_CA06_2001, Year=2006) 
# vectors_2016=c("v_CA16_2397","v_CA16_4890","v_CA16_4894","v_CA16_4897","v_CA16_4901")
# vectors_2011=c("v_CA11N_2562","v_CA11N_2281","v_CA11N_2285","v_CA11N_2288","v_CA11N_2292")
# vectors_2006=c("v_CA06_2000","v_CA06_2049","v_CA06_2050","v_CA06_2053","v_CA06_2055")
# data_2016=get_census("CA16",level="Regions",regions=regions,vectors=vectors_2016,labels="short") %>%
#   mutate(Ratio=(v_CA16_4890*v_CA16_4894+v_CA16_4897*v_CA16_4901)/(v_CA16_4890+v_CA16_4897)*12/v_CA16_2397, Year=2016) 
# data_2011=get_census("CA11",level="Regions",regions=regions,vectors=vectors_2011,labels="short") %>%
#   mutate(Ratio=(v_CA11N_2281*v_CA11N_2285+v_CA11N_2288*v_CA11N_2292)/(v_CA11N_2281+v_CA11N_2288)*12/v_CA11N_2562, Year=2011) 
# data_2006=get_census("CA06",level="Regions",regions=regions,vectors=vectors_2006,labels="short") %>%
#   mutate(Ratio=(v_CA06_2049*v_CA06_2050+v_CA06_2053*v_CA06_2055)/(v_CA06_2049+v_CA06_2053)*12/v_CA06_2000, Year=2006) 

data <- do.call(rbind,list(
  data_2016 %>% select("Region Name", "Ratio", "Year"),
  data_2011 %>% select("Region Name", "Ratio", "Year"),
  data_2006 %>% select("Region Name", "Ratio", "Year")
                      )) %>% mutate(Region=`Region Name`) %>% 
         mutate(Year=factor(Year,levels=c(2006,2011,2016),ordered=TRUE))

g1 <- ggplot(data, 
       aes(x=factor(Year), y=Ratio)) +
  geom_bar(stat="identity",position="dodge", fill="steelblue") +
  scale_y_continuous(labels = scales::percent) +
  labs(x="Year", title="Average Shelter cost to Average Income") +
  geom_text(aes(label=format_percent(Ratio)),vjust=-0.5, position = position_dodge(width = 1), size=text_size) +
  expand_limits(y=max(data$Ratio)*1.15) +
  facet_wrap("Region",ncol=2) +
  theme_bw()
return(g1)
} 

library(grid)
library(gridExtra)

```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4, fig.width=10, dev='svg'}
region=list_census_regions('CA16', quiet=TRUE, use_cache = TRUE) %>%
  filter(level=='CSD',name=='Vancouver') %>% as_census_region_list

grid.arrange(
  grobs=list(affordability_graph_for(region),multiple_graph_for(region)),
  ncol = 2
  #top = 'Comparing Affordability Measures',
  #bottom=""
  )



```

Diverging Narratives that need to be reconciled: At ecological level, it looks like things got worse. At individual levels, it looks like like they got better.

---
# Question 2
Which city has higher incomes, Toronto or Vancouver?

--

```{r, include=FALSE}
caption="StatCan census via cansim and CensusMapper"
format_currency <- function(x){return(paste0("$",format(x,big.mark = ",")))}
regions=list(CSD=c("5915022","3520005"))
```
```{r, message=FALSE, warning=FALSE, include=FALSE}
data_2016 <- get_census(dataset='CA16', regions=regions,
                        vectors=c("v_CA16_2397","v_CA16_2400","v_CA16_2403","v_CA16_2447","v_CA16_2451","v_CA16_2455"),
                        labels="short", geo_format=NA, level='Regions') %>% 
  mutate(Year="2015/2016") %>% 
  rename(`Median Household Income`=v_CA16_2397,
         `Median 1 Person Household Income`=v_CA16_2400,
         `Median 2+ Person Household Income`=v_CA16_2403,
         `Median Family Income`=v_CA16_2447,
         `Median Couple Family`=v_CA16_2451,
         `Median Couple Family with Children`=v_CA16_2455
         )
data_2011 <- get_census(dataset='CA11', regions=regions,
                        vectors=c("v_CA11N_2562","v_CA11N_2567","v_CA11N_2572","v_CA11N_2456","v_CA11N_2462","v_CA11N_2468"), 
                        labels="short", geo_format=NA, level='Regions') %>% 
  mutate(Year="2010/2011") %>% 
  rename(`Median Household Income`=v_CA11N_2562,
         `Median 1 Person Household Income`=v_CA11N_2567,
         `Median 2+ Person Household Income`=v_CA11N_2572,
         `Median Family Income`=v_CA11N_2456,
         `Median Couple Family`=v_CA11N_2462,
         `Median Couple Family with Children`=v_CA11N_2468
         )
data_2006 <- get_census(dataset='CA06', regions=regions,
                        vectors=c("v_CA06_2000","v_CA06_2015","v_CA06_1802","v_CA06_1809"), 
                        labels="short", geo_format=NA, level='Regions') %>% 
  mutate(Year="2005/2006") %>% 
  rename(`Median Household Income`=v_CA06_2000,
         `Median 1 Person Household Income`=v_CA06_2015,
         `Median Family Income`=v_CA06_1802,
         `Median Couple Family`=v_CA06_1809
         ) %>% 
  mutate(
         `Median 2+ Person Household Income`=NA,
         `Median Couple Family with Children`=NA
         )

categories=c("Median Household Income","Median 1 Person Household Income","Median 2+ Person Household Income","Median Family Income","Median Couple Family","Median Couple Family with Children")

data <- do.call(rbind,list(
  data_2016 %>% select("Year", "Region Name",categories),
  data_2011 %>% select("Year","Region Name",categories),
  data_2006 %>% select("Year","Region Name",categories)
  ))
```

```{r income, echo=FALSE, fig.height=4, fig.width=9, message=FALSE, warning=FALSE}
plot_data <- data %>% 
  gather(key="Type", value="Median Income", categories) %>%
  rename(City=`Region Name`) %>%
  mutate(`Household Type` = paste0(Type," ",City)) %>%
  mutate(Year=factor(Year,levels=c("2005/2006","2010/2011","2015/2016"), ordered=TRUE))
ggplot(plot_data, aes(x=Year, y=`Median Income`, group=`Household Type`, color=Type, shape=City, linetype=City, linewidth=2)) +
  scale_color_brewer(palette = "Set2") +
  scale_y_continuous(labels=format_currency) +
  geom_line() + geom_point() +
  labs(title="Median Income Measures", caption=caption) +
      theme_bw()
```

---
# Question 3
What share of Toronto and Vancouver residential properties are owned by owner-occupiers, investors living in Canada and investors living abroad?

--

```{r, message=FALSE, warning=FALSE, include=FALSE}
chsp_data_1 <- getCANSIM("0350001",showLabels = FALSE,raw=TRUE) %>% mutate(Value=as.numeric(Value))
sfs_data <- getCANSIM("2050002",raw=TRUE,showLabels = FALSE) %>% 
  mutate(Value = as.numeric(Value)) %>% 
  type_convert(locale=locale(encoding="Windows-1254")) # yes, CANSIM seriously doesn't use UTF-8!!!
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


sfs_primary_counts <- sfs_data %>% filter(grepl("Vancouver|Toronto",GEO),
                                 AGE=="All ages",
                                 FAMILY=="Economic families and persons not in an economic family",
                                 CHAR=="Number holding asset or debt (number x 1,000)",
                                 Ref_Date=="2016",
                                 FINANCE=="Principal residence") %>%
  select(GEO,INT,Value) %>%
  mutate(Value=Value*1E3,
         GEO=sub(",.+$","",GEO),
         INT=recode(INT,`Lower bound of a 95% confidence interval`="lower",
                          `Upper bound of a 95% confidence interval`="upper"),
         type="SFS") 

library(cancensus)
census_counts <- get_census(dataset='CA16', regions=list(CMA=c("59933","35535")), vectors=c("v_CA16_4890","v_CA16_4896"), labels="short", geo_format=NA, level='Regions') %>% 
  mutate(Value=v_CA16_4890, 
         GEO=gsub(" \\(.+\\)$","",`Region Name`),
         INT="Estimate",
         type="Census")  %>% 
  select(GEO,INT,Value,type)

plot_data <- rbind(sfs_primary_counts,census_counts) %>%
  group_by(GEO) %>% spread(key="INT", value="Value")

# ggplot(plot_data,aes(x=GEO,y=Estimate, fill=type)) +
#   geom_bar(stat="identity", position="dodge") +
#   scale_y_continuous(labels=scales::comma) +
#   geom_errorbar(aes(ymin=lower, ymax=upper),
#                   size=.3,    # Thinner lines
#                   width=.2, position=position_dodge(.9)) +
#   labs(title="Residential Properties",
#        x="CMA",
#        y="Number of Properties",
#       fill="Data Source")
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
chsp_counts <- chsp_data_1 %>% filter(grepl("metropolitan",GEO)) %>%
  filter(NOO=="Total, all owner categories", 
         EST=="Number",
         RES != "Total, all residency status categories", 
         TYPE=="Total, all property types") %>%
  mutate(GEO=sub(",.+$","",GEO),
         type="CHSP",
         INT="Estimate") %>%
  select(GEO,type,RES,INT,Value)
plot_data <- do.call(rbind,list(sfs_primary_counts %>% mutate(RES="Resident"),
                                             census_counts %>% mutate(RES="Resident"),
                                             chsp_counts)) %>%
  group_by(GEO) %>% spread(key="INT", value="Value")


# ggplot(plot_data,aes(x=type,y=Estimate, fill=RES)) +
#   geom_bar(stat="identity", position="stack") +
#   scale_y_continuous(labels=scales::comma) +
#   geom_errorbar(aes(ymin=lower, ymax=upper),
#                   size=.3,    # Thinner lines
#                   width=.2, position=position_dodge(.9)) +
#   facet_wrap("GEO") +
#   labs(title="Residential Properties",
#        x="CMA",
#        y="Number of Properties",
#        fill="Data Source")

```


```{r, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
sfs_estimates <- sfs_primary_counts %>% filter(INT=="Estimate")
chsp_res1_counts <- chsp_counts %>% filter(RES=="Resident") %>% mutate(
  Value=ifelse(GEO=="Vancouver",
                     (census_counts$Value[census_counts$GEO=="Vancouver"]+sfs_estimates$Value[sfs_estimates$GEO=="Vancouver"])/2,
                     (census_counts$Value[census_counts$GEO=="Toronto"]+sfs_estimates$Value[sfs_estimates$GEO=="Toronto"])/2),
  RES="Resident owner-occupier")
chsp_res2_counts <- chsp_counts %>% filter(RES=="Resident") %>% mutate(
  Value=ifelse(GEO=="Vancouver",
                     Value-chsp_res1_counts$Value[chsp_res1_counts$GEO=="Vancouver"],
                     Value-chsp_res1_counts$Value[chsp_res1_counts$GEO=="Toronto"]),
  RES="Local investor")



plot_data <- do.call(rbind,list(chsp_counts %>% filter(RES=="Non-resident") %>% mutate(RES="Overseas investor"),
                                chsp_res1_counts,
                                chsp_res2_counts)) %>%
  mutate(RES=factor(RES,levels=rev(c("Resident owner-occupier","Local investor","Overseas investor")),ordered=TRUE))


ggplot(plot_data,aes(x=GEO,y=Value, fill=RES)) +
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(labels=scales::percent) +
  scale_fill_brewer(palette = "Set2") + 
  labs(title="Residential Properties",
       x="CMA",
       y="Share of Properties",
       fill="Owner")

```


---
class: center, middle

Thanks for bearing with me. These slides are online at https://mountainmath.ca/working_with_census.html and the R notebook that made the, including the code, is linked at GitHub.

???
Our discussion rarely move beyond presenting a simple quotient. We need to move beyond viewing the world through single census variables or simple percentages and dig deeper into the very complex issues we are facing.
